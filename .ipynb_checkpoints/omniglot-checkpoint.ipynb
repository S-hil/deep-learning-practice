{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this function will read all persons' training images, detect face from each image\n",
    "#and will return two lists of exactly same size, one list \n",
    "#of faces and another list of labels for each face\n",
    "def prepare_training_data(data_folder_path):\n",
    "    count= 0\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    #list to hold all subject faces\n",
    "    images = []\n",
    "    #list to hold labels for all subjects\n",
    "    labels = []\n",
    "    lang_count=0\n",
    "# First for loop\n",
    "    for lang_name in dirs:\n",
    "        dirs = os.listdir(data_folder_path+\"/\"+lang_name)\n",
    "#         Second For loop\n",
    "        for char_name in dirs:\n",
    "            chars = os.listdir(data_folder_path+\"/\"+lang_name+\"/\"+char_name)\n",
    "            count+=1\n",
    "#             Third for loop\n",
    "            for image_name in chars:\n",
    "\n",
    "                #sample image path = training-data/s1/1.pgm\n",
    "                image_path = data_folder_path+\"/\"+lang_name+\"/\"+char_name+\"/\"+image_name\n",
    "                #read image\n",
    "                image = plt.imread(image_path)\n",
    "                label=[lang_name,char_name,image_name,int(count)]\n",
    "                #display an image window to show the image \n",
    "        #             cv2.imshow(\"Showing image...\", image)\n",
    "        #             cv2.waitKey(100)\n",
    "        #             plt.imshow(image)\n",
    "\n",
    "                if image is not None:\n",
    "                    images.append(image)\n",
    "                    labels.append(label)\n",
    "\n",
    "        #             cv2.destroyAllWindows()\n",
    "        #             cv2.waitKey(1)\n",
    "        #             cv2.destroyAllWindows()\n",
    "\n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a43b12048>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a4184efd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dirs = os.listdir(\"omniglot/images_background_small1\")\n",
    "images,labels= prepare_training_data(\"omniglot/images_background_small1\")\n",
    "plt.imshow(images[6])\n",
    "# plt.imshow(tf.image.rgb_to_grayscale(images[56],None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Korean', 'character11', '0653_07.png', 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a418f25c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[6])\n",
    "print(labels[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2720, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels=np.array(labels)\n",
    "y = labels[:,3]\n",
    "y = [int(i) for i in y]\n",
    "y=np.array(y)\n",
    "y=y.reshape((np.shape(y)[0], 1))\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=np.max(y)\n",
    "y2 = to_categorical(y, num_classes = temp+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 =np.shape(images[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 2\n",
    "images=np.array(images)\n",
    "x_train=images.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train\n",
    "x_train = x_train.reshape(-1,105,105,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (105,105,1)))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.40))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(137, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30 \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "76/76 [==============================] - 586s 8s/step - loss: 4.9185 - acc: 0.0070 - val_loss: 4.9272 - val_acc: 0.0037\n",
      "Epoch 2/30\n",
      "76/76 [==============================] - 561s 7s/step - loss: 4.9191 - acc: 0.0066 - val_loss: 4.9366 - val_acc: 0.0037\n",
      "Epoch 3/30\n",
      "76/76 [==============================] - 585s 8s/step - loss: 4.9190 - acc: 0.0078 - val_loss: 4.9302 - val_acc: 0.0037\n",
      "Epoch 4/30\n",
      "76/76 [==============================] - 540s 7s/step - loss: 4.9168 - acc: 0.0066 - val_loss: 4.9734 - val_acc: 0.0037\n",
      "Epoch 5/30\n",
      "76/76 [==============================] - 541s 7s/step - loss: 4.9185 - acc: 0.0066 - val_loss: 4.9299 - val_acc: 0.0074\n",
      "Epoch 6/30\n",
      "76/76 [==============================] - 540s 7s/step - loss: 4.8840 - acc: 0.0181 - val_loss: 4.8402 - val_acc: 0.0147\n",
      "Epoch 7/30\n",
      "76/76 [==============================] - 542s 7s/step - loss: 4.7706 - acc: 0.0263 - val_loss: 4.5975 - val_acc: 0.0257\n",
      "Epoch 8/30\n",
      "76/76 [==============================] - 541s 7s/step - loss: 4.5719 - acc: 0.0424 - val_loss: 4.1557 - val_acc: 0.0809\n",
      "Epoch 9/30\n",
      "76/76 [==============================] - 540s 7s/step - loss: 4.3373 - acc: 0.0621 - val_loss: 3.5942 - val_acc: 0.1765\n",
      "Epoch 10/30\n",
      "76/76 [==============================] - 540s 7s/step - loss: 4.0197 - acc: 0.0958 - val_loss: 3.2070 - val_acc: 0.2794\n",
      "Epoch 11/30\n",
      "76/76 [==============================] - 541s 7s/step - loss: 3.7310 - acc: 0.1398 - val_loss: 2.6887 - val_acc: 0.2868\n",
      "Epoch 12/30\n",
      "76/76 [==============================] - 542s 7s/step - loss: 3.5321 - acc: 0.1554 - val_loss: 2.5850 - val_acc: 0.4044\n",
      "Epoch 13/30\n",
      "76/76 [==============================] - 542s 7s/step - loss: 3.3288 - acc: 0.1949 - val_loss: 2.2846 - val_acc: 0.4228\n",
      "Epoch 14/30\n",
      "76/76 [==============================] - 571s 8s/step - loss: 3.2046 - acc: 0.2105 - val_loss: 2.1209 - val_acc: 0.4632\n",
      "Epoch 15/30\n",
      "76/76 [==============================] - 594s 8s/step - loss: 3.0706 - acc: 0.2307 - val_loss: 1.9853 - val_acc: 0.4816\n",
      "Epoch 16/30\n",
      "76/76 [==============================] - 599s 8s/step - loss: 2.9695 - acc: 0.2488 - val_loss: 1.7764 - val_acc: 0.5294\n",
      "Epoch 17/30\n",
      "76/76 [==============================] - 577s 8s/step - loss: 2.7923 - acc: 0.2730 - val_loss: 1.6766 - val_acc: 0.5588\n",
      "Epoch 18/30\n",
      "76/76 [==============================] - 553s 7s/step - loss: 2.7472 - acc: 0.2874 - val_loss: 1.6048 - val_acc: 0.5772\n",
      "Epoch 19/30\n",
      "76/76 [==============================] - 581s 8s/step - loss: 2.6360 - acc: 0.3076 - val_loss: 1.5220 - val_acc: 0.6250\n",
      "Epoch 20/30\n",
      "76/76 [==============================] - 559s 7s/step - loss: 2.5269 - acc: 0.3248 - val_loss: 1.4019 - val_acc: 0.6434\n",
      "Epoch 21/30\n",
      "76/76 [==============================] - 574s 8s/step - loss: 2.3941 - acc: 0.3627 - val_loss: 1.2912 - val_acc: 0.6471\n",
      "Epoch 22/30\n",
      "76/76 [==============================] - 571s 8s/step - loss: 2.3874 - acc: 0.3623 - val_loss: 1.3461 - val_acc: 0.6544\n",
      "Epoch 23/30\n",
      "76/76 [==============================] - 589s 8s/step - loss: 2.2804 - acc: 0.3783 - val_loss: 1.2544 - val_acc: 0.6324\n",
      "Epoch 24/30\n",
      " 2/76 [..............................] - ETA: 7:20 - loss: 3.0378 - acc: 0.2344"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-3f0e02f6734d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                               , callbacks=[learning_rate_reduction])\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('my_omniModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('my_omniModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
